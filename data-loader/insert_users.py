import csv
import os
import time
import multiprocessing
from faker import Faker

# Configuration
NUM_USERS = 40_000_000            # –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
CSV_FILE = "/app/shared/users.csv"  # –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —É —Å–ø—ñ–ª—å–Ω–æ–º—É —Ç–æ–º—ñ (–¥–æ—Å—Ç—É–ø–Ω–æ–º—É –æ–±–æ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º)
NUM_PROCESSES = max(1, int(multiprocessing.cpu_count() * 0.9))
BATCH_SIZE = 500_000             # –ó–∞–ø–∏—Å—É—î–º–æ —É CSV –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ 500–ö —Ä—è–¥–∫—ñ–≤

fake = Faker()
Faker.seed(42)

def generate_unique_email(index):
  """–ì–µ–Ω–µ—Ä—É—î —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π email —ñ–∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —ñ–Ω–¥–µ–∫—Å—É —Ç–∞ –≤–∏–ø–∞–¥–∫–æ–≤–æ–≥–æ —Ä—è–¥–∫–∞."""
  random_part = fake.lexify(text="????").lower()  # –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —Ä—è–¥–æ–∫ –∑ 4 –±—É–∫–≤
  return f"{random_part}{index}@example.com"

def count_existing_records():
  """–†–∞—Ö—É—î–º–æ, —Å–∫—ñ–ª—å–∫–∏ —Ä—è–¥–∫—ñ–≤ –≤–∂–µ —î —É CSV-—Ñ–∞–π–ª—ñ (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)."""
  if not os.path.exists(CSV_FILE):
    return 0
  with open(CSV_FILE, "r") as f:
    return sum(1 for _ in f) - 1  # –≤—ñ–¥–Ω—ñ–º–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫

def generate_users(start, end, queue):
  """–ì–µ–Ω–µ—Ä—É—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º–∏ email —Ç–∞ –Ω–∞–¥—Å–∏–ª–∞—î–º–æ —ó—Ö —É —á–µ—Ä–≥—É –ø–∞–∫–µ—Ç–∞–º–∏."""
  print(f"üü¢ Process {start}-{end} started...")
  users = []
  for i in range(start, end):
    name = fake.name()
    email = generate_unique_email(i)
    dob = fake.date_of_birth(minimum_age=18, maximum_age=90).strftime("%Y-%m-%d")
    users.append([name, email, dob])
    if len(users) >= BATCH_SIZE:
      queue.put(users)
      print(f"‚úÖ Process {start}-{end} sent {len(users)} users to queue")
      users = []  # –û—á–∏—â–∞—î–º–æ —Å–ø–∏—Å–æ–∫ –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –±–∞—Ç—á—É
  if users:
    queue.put(users)
    print(f"‚úÖ Process {start}-{end} sent {len(users)} remaining users to queue")
  print(f"‚úÖ Process {start}-{end} finished generating users.")

def write_csv(queue, append_mode):
  """–ó–∞–ø–∏—Å—É—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ —ñ–∑ —á–µ—Ä–≥–∏ —É CSV-—Ñ–∞–π–ª."""
  mode = "a" if append_mode else "w"
  print(f"üü¢ Writing data to {CSV_FILE} (mode: {mode})...")
  with open(CSV_FILE, mode, newline="") as f:
    writer = csv.writer(f)
    if not append_mode:
      writer.writerow(["name", "email", "date_of_birth"])
    while True:
      users = queue.get()
      if users is None:
        break
      print(f"üü¢ Writing batch of {len(users)} users to CSV...")
      writer.writerows(users)
  print(f"‚úÖ CSV file successfully written to {CSV_FILE}!")

def generate_csv():
  """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: –ø–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö —ñ –≥–µ–Ω–µ—Ä—É—î –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤."""
  print("üü¢ Checking if users.csv already exists...")
  existing_users = count_existing_records()
  print(f"üü¢ Found {existing_users} existing records in users.csv")
  if existing_users >= NUM_USERS:
    print(f"‚úÖ users.csv already contains {existing_users} users. Skipping generation.")
    return
  missing_users = NUM_USERS - existing_users
  print(f"üü¢ Need to generate {missing_users} users...")
  start_time = time.time()

  with multiprocessing.Manager() as manager:
    queue = manager.Queue()
    processes = []
    chunk_size = missing_users // NUM_PROCESSES
    for i in range(existing_users, NUM_USERS, chunk_size):
      p = multiprocessing.Process(target=generate_users, args=(i, min(i + chunk_size, NUM_USERS), queue))
      processes.append(p)
      p.start()

    writer_process = multiprocessing.Process(target=write_csv, args=(queue, existing_users > 0))
    writer_process.start()

    for p in processes:
      p.join()
    queue.put(None)  # –°–∏–≥–Ω–∞–ª –¥–ª—è –∑—É–ø–∏–Ω–∫–∏ –∑–∞–ø–∏—Å—É
    writer_process.join()

  end_time = time.time()
  print(f"‚úÖ CSV file updated successfully in {round(end_time - start_time, 2)} seconds!")

if __name__ == "__main__":
  generate_csv()